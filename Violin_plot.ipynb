{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import feets.preprocess\n",
    "from scipy import stats\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import feets\n",
    "from ipykernel import kernelapp as app\n",
    "import os\n",
    "\n",
    "\n",
    "\n",
    "script_dir = os.path.dirname('Results/')\n",
    "results_dir = os.path.join(script_dir, 'Images/')\n",
    "\n",
    "if not os.path.isdir(results_dir):\n",
    "    os.makedirs(results_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://raw.githubusercontent.com/MachineLearningUniandes/MANTRA/master/data/lightcurves/transient_lightcurves.csv\"\n",
    "url1 = 'https://raw.githubusercontent.com/MachineLearningUniandes/MANTRA/master/data/lightcurves/transient_labels.csv'\n",
    "url2 = 'https://raw.githubusercontent.com/MachineLearningUniandes/MANTRA/master/data/lightcurves/transient_info.txt'\n",
    "transient_lc = pd.read_csv(url)\n",
    "transient_labels = pd.read_csv(url1)\n",
    "transient_info = pd.read_table(url2,skiprows=1,names=['CRTS_ID' ,'RA' ,'Dec','UT_Date','Mag','CSS_images' ,'SDSS',\n",
    "                                                      'Others' ,'Followed' ,'Last','LC','FC','Classification'])\n",
    "\n",
    "transient_info.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from sklearn.ensemble import IsolationForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading in the feature.csv data\n",
    "ft_data = pd.read_csv('features.csv',skiprows=1,names= ['Amplitude', 'AndersonDarling', 'Autocor_length', 'Beyond1Std',\n",
    "                                                  'CAR_sigma', 'Con', 'Eta_e', 'Freq1_harmonics_rel_phase_1',\n",
    "                                                  'LinearTrend', 'MaxSlope', 'Mean', 'Period_fit', \n",
    "                                                  'SlottedA_length','SmallKurtosis', 'StructureFunction_index_21'\n",
    "                                                  ,'ID','Class'])\n",
    "\n",
    "\n",
    "ft_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = ['Amplitude', 'AndersonDarling', 'Autocor_length', 'Beyond1Std',\n",
    "                                                  'CAR_sigma', 'Con', 'Eta_e', 'Freq1_harmonics_rel_phase_1',\n",
    "                                                  'LinearTrend', 'MaxSlope', 'Mean', \n",
    "                                                  'SlottedA_length','SmallKurtosis', 'StructureFunction_index_21'\n",
    "                                                  ]\n",
    "\n",
    "X = ft_data[params]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=IsolationForest(n_estimators=400, max_samples='auto',max_features=1.0)\n",
    "x=model.fit(X)\n",
    "\n",
    "\n",
    "\n",
    "pred_cls = []\n",
    "# Predicting the anomalies\n",
    "ft_data['iforest'] = pd.Series(model.predict(X))\n",
    "ft_data['iforest_Counts'] = ft_data['iforest'].map({1:0,-1:1})\n",
    "# Counting the detected anomalies\n",
    "print(ft_data['iforest'].value_counts())\n",
    "\n",
    "# Analysing the predicted anomalies\n",
    "pred=ft_data.loc[ft_data['iforest'] == -1]\n",
    "for i in range(len(pred.ID)):\n",
    "    \n",
    "    \n",
    "#     plt.figure(figsize=(16,4))\n",
    "#     plt.xlabel('MJD')\n",
    "#     plt.ylabel('Mag')\n",
    "    lc = transient_lc[transient_lc['ID']==pred.ID.iloc[i]]\n",
    "    \n",
    "#     print(len(lc),pred.Class.iloc[i],pred.ID.iloc[i])\n",
    "    pred_cls.append(pred.Class.iloc[i])\n",
    "#     plt.errorbar(lc.MJD,lc.Mag,yerr=lc.Magerr,fmt='.r',label=pred.Class.iloc[i])\n",
    "#     plt.legend()\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn_score_anomalies = model.decision_function(X)\n",
    "\n",
    "# print(sklearn_score_anomalies)\n",
    "\n",
    "x = [i  for i in sklearn_score_anomalies]\n",
    "\n",
    "# len(ft_data[x])\n",
    "\n",
    "anomalies_scr=sklearn_score_anomalies\n",
    "anomalies_cls = ft_data.Class\n",
    "\n",
    "\n",
    "# Getting the unique classes detected as anomalous\n",
    "ML_unq_cls=np.unique(pred_cls)\n",
    "# x = [i < 0 for i in sklearn_score_anomalies]\n",
    "# anomalies_scr=sklearn_score_anomalies[x]\n",
    "# anomalies_cls = ft_data.Class[x]\n",
    "# anomalies_ID = ft_data.ID[x]\n",
    "\n",
    "# Getting the number of objects in each anomalous class \n",
    "# based on the transient label data\n",
    "len_anm = []\n",
    "for i in ML_unq_cls:\n",
    "    \n",
    "    lb = transient_labels[transient_labels['Classification']==i]   \n",
    "    len_anm.append(len(lb))\n",
    "\n",
    "\n",
    "# Sorting the classes in ascending based on the number of\n",
    "# objects in each class (i.e most anomalous to least anomalous)\n",
    "cls = []  \n",
    "for i in range(0,max(len_anm)+1): \n",
    "    \n",
    "    for j in range(len(len_anm)): \n",
    "        \n",
    "        if len_anm[j] == i: \n",
    "            cls.append(ML_unq_cls[j])\n",
    "            \n",
    "                        \n",
    "# Calculating the average and std of the anom\n",
    "# scores\n",
    "\n",
    "sstd,aave = [],[] ; catgories = []; scr1=[]\n",
    "for j in range(len(cls)):\n",
    "    scr = []\n",
    "    for i in range(len(anomalies_cls)):\n",
    "    \n",
    "        if anomalies_cls.iloc[i] == cls[j]:\n",
    "            \n",
    "            scr.append(anomalies_scr[i])\n",
    "            scr1.append(anomalies_scr[i])\n",
    "            \n",
    "    catgories.append(scr)\n",
    "            \n",
    "#             print(anomalies_cls.iloc[i],anomalies_scr[i])\n",
    "#     print(scr,np.std(scr))       \n",
    "    std=np.std(scr)\n",
    "    ave=np.average(scr)   \n",
    "    sstd.append(std);aave.append(ave)\n",
    "    \n",
    "#     print(ave,std)\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "# Plotting the anomalous objects based on their score \n",
    "plt.rcParams.update({'font.size': 24})\n",
    "plt.figure(figsize=(15,8))\n",
    "df = pd.DataFrame({\"id\":cls, \n",
    "                   \"score\":aave,\n",
    "                   'error':sstd\n",
    "                   })\n",
    "plt.errorbar(np.arange(len(df['id'])), df['score'],yerr=df['error'],fmt='-ro',ecolor='b',label='ave score',linewidth=2.2)\n",
    "ax = plt.gca()\n",
    "ax.xaxis.set_ticks(np.arange(len(df['id'])))\n",
    "ax.xaxis.set_ticklabels(df['id'], rotation=90)\n",
    "plt.xlabel(\"Class\")\n",
    "plt.ylabel(\"Anomaly_score\")\n",
    "plt.gca().invert_yaxis()\n",
    "plt.legend()\n",
    "plt.savefig(results_dir + 'ave_score_all.png',bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd \n",
    "import pandas as pd \n",
    "  \n",
    "# both lists, with columns specified \n",
    "df = pd.DataFrame(list(zip(anomalies_scr, anomalies_cls)), \n",
    "               columns =['anomaly_score', 'class']) \n",
    "\n",
    "\n",
    "\n",
    "plt.figure(figsize=(16,6))\n",
    "x = sns.violinplot(x=\"class\", y=\"anomaly_score\", data=df,gridsize=200,order=cls,width=0.8)\n",
    "plt.savefig('violin_plot.png')\n",
    "# plt.xlabel('m')\n",
    "plt.axhline(0,color='black',ls=':')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}